# Minimal Playground 配置文件
# 这是一个最小化的 EvoMaster 示例，展示如何用 ~100 行代码实现自主科学发现

# ============================================
# LLM 配置（可用 ${VAR} 引用 .env 中的环境变量，见 .env.template）
# LiteLLM / Azure 使用 OpenAI 兼容接口，provider 填 openai 即可
# ============================================
llm:
  # LiteLLM Proxy（推荐：无 OpenAI 时用此项）
  # model 须为代理允许的型号；.env 中设置 GPT_CHAT_MODEL 可覆盖，否则用默认 azure/gpt-5-chat
  litellm:
    provider: "openai"
    model: "${GPT_CHAT_MODEL:-azure/gpt-5-chat}"
    api_key: "${LITELLM_PROXY_API_KEY}"
    base_url: "${LITELLM_PROXY_API_BASE}"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  # Azure OpenAI（model 须为代理允许的型号）
  azure:
    provider: "openai"
    model: "${GPT_CHAT_MODEL:-azure/gpt-5-chat}"
    api_key: "${AZURE_API_KEY}"
    base_url: "${AZURE_API_BASE}"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  openai:
    provider: "openai"
    model: "gpt-5.2"
    api_key: "${OPENAI_API_KEY}"
    base_url: "${OPENAI_BASE_URL}"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  anthropic:
    provider: "anthropic"
    model: "claude-haiku-4-5-20251001"
    api_key: "${ANTHROPIC_API_KEY}"
    base_url: "${ANTHROPIC_BASE_URL}"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  default: "litellm"
# ============================================
# 多智能体配置
# ============================================
# 多智能体系统中，每个Agent都有独立的配置
# 单智能体时，只填写一个agent配置即可
agents:
  # General Agent - 负责规划任务（llm 填 litellm / azure / openai 等，与上面 llm 块对应）
  general:
    llm: "litellm"
    max_turns: 50
    enable_tools: true  # General Agent使用工具调用
    
    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5
    
    # 提示词配置
    system_prompt_file: "prompts/system_prompt.txt"
    user_prompt_file: "prompts/user_prompt.txt"


# ============================================
# MCP 配置
# ============================================
mcp:
  # MCP 配置文件路径（相对于 config_dir 或绝对路径）
  config_file: "../mcp_config.json"

  # 是否启用 MCP（可选，默认 true）
  enabled: True

# ============================================
# Session 配置
# ============================================
session:
  # Session 类型：local 或 docker
  type: "local"  # 可选值: "local" 或 "docker"
  
  # 本地 Session 配置
  local:
    working_dir: "./playground/minimal/workspace"
    timeout: 60
    # GPU 设备配置（可选）
    # 可选值：
    #   - null: 不使用 GPU 限制（使用所有可用 GPU）
    #   - "2": 只使用 GPU 2
    #   - ["0", "1"]: 使用 GPU 0 和 1
    gpu_devices: "2"  # 示例：使用 GPU 2
    
    # CPU 设备配置（可选）
    # 可选值：
    #   - null: 不使用 CPU 限制（使用所有可用 CPU）
    #   - "0-15": 使用 CPU 0 到 15
    #   - [0, 1, 2, 3]: 使用 CPU 0, 1, 2, 3
    cpu_devices: "0-15"  # 示例：使用 CPU 0-15
    # 软链接配置（可选）
    # 将源目录下的所有文件和文件夹软链接到工作空间的指定位置
    # 格式：{源目录路径: 工作空间内的目标路径}
    # 目标路径是相对于工作空间的相对路径
    # 示例：
    # symlinks:
    #   "/data/exp_data/demo1bench/aerial-cactus-identification/prepared/public/": "input"
    symlinks: {}
  
  # Docker Session 配置
  docker:
    # Docker 镜像
    image: "evomaster/base:latest"
    
    # 容器名称（None 自动生成）
    container_name: null
    
    # 使用已存在的容器（如果设置，则使用该容器而不创建新容器）
    use_existing_container: null
    
    # 工作目录（容器内）
    working_dir: "/workspace"
    
    # 资源限制
    memory_limit: "64g"  # 内存限制，如 "4g", "8g"
    cpu_limit: 16.0      # CPU 限制（核数）
    gpu_devices: "0"   # GPU 设备，可选值：
                        #   - null: 不使用 GPU
                        #   - "all": 使用所有 GPU
                        #   - "0": 使用 GPU 0
                        #   - ["0", "1"]: 使用 GPU 0 和 1
    
    # 网络模式
    network_mode: "host"  # bridge, host, none
    
    # 挂载卷（将本地目录挂载到容器）
    # 格式：{本地路径: 容器路径}
    # 示例：
    # volumes:
    #   "./workspace": "/workspace"
    volumes: {"./playground/minimal/workspace":"/workspace"}
    
    # 环境变量
    # 示例：
    # env_vars:
    #   PYTHONPATH: "/workspace"
    env_vars: {}
    
    # 容器生命周期
    auto_remove: false   # true: 容器结束后自动删除，false: 保留容器
    
    # 超时时间（秒）在需要长时间执行的任务中，需要适当延长超时时间。
    timeout: 300

# ============================================
# Env 配置（环境管理）
# ============================================
env:
  # 集群配置（本地模式，最小化）
  cluster:
    debug_pool:
      type: "cpu"
      max_concurrent: 1
    train_pool:
      type: "cpu"
      max_concurrent: 1

  # Docker 配置（本地模式）
  docker:
    base_image: "python:3.11-slim"
    registry: "docker.io"
    pull_policy: "if_not_present"

  # 作业调度配置
  scheduler:
    type: "local"
    queue_timeout: 300
    retry_failed: false
    max_retries: 1

# ============================================
# 系统提示词配置
# ============================================
# 从文件加载 system prompt（方便维护和版本控制）
# 路径相对于 config_dir (configs/minimal/)
system_prompt_file: "../../../playground/minimal/prompts/system_prompt.txt"

# ============================================
# LLM 输出显示配置
# ============================================
llm_output:
  # 是否在终端实时显示 LLM 输出
  show_in_console: true
  
  # 是否在日志文件中记录 LLM 输出
  log_to_file: true

# ============================================
# 日志配置
# ============================================
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null
  console: true
  
  # 日志文件保存路径（程序运行完成后保存）
  # 如果为 null，则不保存日志文件
  # 如果设置了路径，程序运行完成后会将日志保存到该路径
  log_path: "./logs/evomaster.log"

# ============================================
# 其他配置
# ============================================
project_root: "."
workspace: "./workspace"
results_dir: "./results"
debug: false
